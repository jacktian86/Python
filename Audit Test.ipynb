{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from pandas import DataFrame, date_range, read_csv, read_excel, concat, isnull\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime\n",
      "import numpy as np\n",
      "import ols\n",
      "import statsmodels.api as sm\n",
      "from datetime import datetime, timedelta\n",
      "import os as os\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_results = read_excel('2013 Launch Results.xlsx', 'Sheet1')\n",
      "\n",
      "df_results_parse = df_results.ix[:,['DealerExternalId','AuditCompletedOn','AuditOutstandingBalance','clientCode','UnitOutstandingBalance']]\n",
      "df_results_parse = df_results_parse[df_results_parse['clientCode']=='Sold and Unpaid']\n",
      "\n",
      "df_results_parse['DealerExternalId'] = df_results_parse['DealerExternalId'].apply(str)\n",
      "df_results_parse['DealerExternalId']= [item.strip('0.') for item in df_results_parse['DealerExternalId']] \n",
      "\n",
      "df_results_parse['AuditCompletedOn']=df_results_parse['AuditCompletedOn'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S.%f'))\n",
      "\n",
      "mask = pd.Series([item.year>2012 and item.month>2 for item in df_results_parse['AuditCompletedOn']], index = df_results_parse.index)\n",
      "df_results_parse = df_results_parse[mask]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_results_parse = df_results_parse.groupby(['DealerExternalId','AuditCompletedOn']).sum()\n",
      "\n",
      "df_results_parse = df_results_parse.reset_index().groupby('DealerExternalId').mean()\n",
      "df_results_parse = df_results_parse.ix[:,'UnitOutstandingBalance']\n",
      "\n",
      "df_test=read_excel('IntelliCheck Data_by Week 2 13 2014.xlsx', 'Sheet1')\n",
      "df_test['Customer Number'] = df_test['Customer Number'].apply(str)\n",
      "df_test['Customer Number']= [item.strip('0.') for item in df_test['Customer Number']] "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Metric_Analysis = df_test.ix[:,['Customer Number', 'Monthly Volume','Monthly Payments','Weekly Beg Balance', 'Weekly Percent Paid', 'Monthly Percent Paid', 'Credit Limit', 'CBR Weighted Score']]\n",
      "\n",
      "Vol_index = Metric_Analysis.groupby('Customer Number').std()\n",
      "Vol_index = Vol_index.rename(columns = {'Monthly Percent Paid':'Monthly Paid Vol', 'Weekly Percent Paid':'Weekly Paid Vol', 'Weekly Beg Balance':'Weekly Balance Vol'})\n",
      "Vol_index = Vol_index.ix[:,['Monthly Paid Vol', 'Weekly Paid Vol', 'Weekly Balance Vol']]\n",
      "\n",
      "Mean_index = Metric_Analysis.groupby('Customer Number').mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Metrics_combined = Vol_index.join(Mean_index, how='inner')\n",
      "Metrics_combined['Results'] = df_results_parse\n",
      "Metrics_combined = Metrics_combined.fillna(0)\n",
      "Metrics_combined['SAU Ratio'] = Metrics_combined['Results']/Metrics_combined['Weekly Beg Balance']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " def error_check(func):\n",
      "    def checker(results, theo, Score, watermark):\n",
      "        \n",
      "        if type(Score) == list:\n",
      "            new_Score = np.array(Score)\n",
      "        else:\n",
      "            new_Score = Score   \n",
      "        if new_Score.max()>theo.max():\n",
      "            final = func(results, theo, Score, watermark)\n",
      "        else:\n",
      "            final = func(results, theo, np.linspace(new_Score.min(), theo.max(), 10), watermark)\n",
      "        \n",
      "        return final\n",
      "    return checker\n",
      "    \n",
      "@error_check\n",
      "def Tester(results, theo, Score, watermark):\n",
      "    \n",
      "    Matrix_list = []\n",
      "    \n",
      "    for item in Score:\n",
      "        Bad_Identified = sum([1 if (a>watermark) and (b<item) else 0 for a,b in zip(results, theo)])\n",
      "        Falsely_Accused = sum([1 if (a==0) and (b<item) else 0 for a,b in zip(results, theo)])\n",
      "        Line_item = tuple([Bad_Identified, Falsely_Accused, Bad_Identified*1.0/(Bad_Identified+Falsely_Accused)])\n",
      "        Matrix_list.append(Line_item)\n",
      "    \n",
      "    return pd.DataFrame(Matrix_list, columns = ['Correct', 'Incorrect', 'Ratio'], index=Score)    \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Final_results = Tester(Metrics_combined['Results'],Metrics_combined['CBR Weighted Score'])\n",
      "Optimize = Final_results.loc[Final_results['Difference'] == Final_results['Difference'].max()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Test_cor = Metrics_combined\n",
      "Test_cor = Test_cor[Test_cor['CBR Weighted Score']!=0]\n",
      "Test_cor = Test_cor[Test_cor['DnB - CCS']!=0]\n",
      "Test_cor = Test_cor[Test_cor['DnB - SBRI Loan']!=0]\n",
      "\n",
      "Test_cor = Test_cor.ix[:,['Theo','SAU Ratio','CBR Weighted Score','DnB - CCS','DnB - SBRI Loan']]\n",
      "\n",
      "Metrics_combined = Metrics_combined[Metrics_combined['CBR Weighted Score']!=0]\n",
      "Metrics_combined['Results'] = Metrics_combined['Results'].fillna(0)\n",
      "Metrics_combined = Metrics_combined.dropna(axis=0)\n",
      "\n",
      "Regressors = Metrics_combined.ix[:,:10]\n",
      "Binary_result = [1 if item>0 else 0 for item in Metrics_combined['Results']]\n",
      "logit = sm.Logit(Binary_result, Regressors)\n",
      "result = logit.fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Tester(Metrics_combined['Results'], result.fittedvalues, np.arange(-2,6,1),0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Tester(Metrics_combined['Results'], Metrics_combined['CBR Weighted Score'], range(500,900,25), 0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}